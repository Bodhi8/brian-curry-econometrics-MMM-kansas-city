{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2823e3af",
   "metadata": {},
   "source": [
    "\n",
    "# Time‑Series Forecasting — Python Notebook\n",
    "\n",
    "**When to Use**  \n",
    "- You need to **predict future values** (sales, demand, traffic) from historical observations and optional exogenous drivers (price, promos, holidays).  \n",
    "- Planning **inventory**, **staffing**, and **media pacing** where lead times matter.\n",
    "\n",
    "**Best Application**  \n",
    "- Stable seasonal patterns (daily/weekly/monthly) with clear trend/seasonality.  \n",
    "- **Scenario forecasts** with exogenous regressors (promotions, macro indicators).  \n",
    "- **Forecast combinations** to reduce model risk.\n",
    "\n",
    "**When Not to Use**  \n",
    "- Highly volatile series with **frequent structural breaks** and minimal history (consider judgmental forecasting or causal models/experiments).  \n",
    "- When the business question is **incrementality/causality** rather than prediction error—use causal inference instead.\n",
    "\n",
    "**How to Interpret Results**  \n",
    "- Compare models via **out‑of‑sample error** (MAE/MAPE/RMSE) from **rolling cross‑validation**.  \n",
    "- Inspect **residual diagnostics** for autocorrelation and bias.  \n",
    "- Coefficients in regression‑with‑ARIMA errors (SARIMAX) show **associations** with the target, not necessarily causality.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb1025a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from statsmodels.tsa.seasonal import STL\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error, mean_squared_error\n",
    "\n",
    "pd.set_option('display.max_columns', 120)\n",
    "plt.rcParams['figure.figsize'] = (8,4)\n",
    "rng = np.random.default_rng(123)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f01215",
   "metadata": {},
   "source": [
    "### Data: Synthetic weekly retail sales with seasonality, promo, price index, and holiday spikes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67dc3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 3 years of weekly data\n",
    "weeks = pd.date_range('2022-01-02', periods=156, freq='W-SUN')\n",
    "t = np.arange(len(weeks))\n",
    "\n",
    "# Components: trend, seasonality, noise\n",
    "trend = 200 + 0.6 * t\n",
    "seasonal = 20 * np.sin(2 * np.pi * t / 52) + 10 * np.sin(2 * np.pi * t / 26)\n",
    "\n",
    "# Promo flag ~20% of weeks, PriceIndex around 100 +/- 5, MacroIndex around 50 +/- 3\n",
    "promo = (rng.random(len(t)) < 0.2).astype(int)\n",
    "price_index = 100 + rng.normal(0, 4, size=len(t))\n",
    "macro_index = 50 + 0.3*np.sin(2*np.pi*t/52) + rng.normal(0,1.5,size=len(t))\n",
    "\n",
    "# Holiday spikes around late Nov/Dec weeks\n",
    "holiday = ((weeks.month==11) & (weeks.week>=47)) | (weeks.month==12)\n",
    "holiday = holiday.astype(int)\n",
    "\n",
    "# Generate sales with effects\n",
    "sales = (trend + seasonal\n",
    "         + 15*promo\n",
    "         - 0.8*(price_index-100)\n",
    "         + 0.9*(macro_index-50)\n",
    "         + 25*holiday\n",
    "         + rng.normal(0, 8, size=len(t)))\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'date': weeks,\n",
    "    'sales': sales,\n",
    "    'promo': promo,\n",
    "    'price_index': price_index,\n",
    "    'macro_index': macro_index,\n",
    "    'holiday': holiday\n",
    "}).set_index('date')\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352de462",
   "metadata": {},
   "source": [
    "### STL Decomposition (diagnostics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f7d4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "stl = STL(df['sales'], period=52)\n",
    "res = stl.fit()\n",
    "res.trend.head(), res.seasonal.head(), res.resid.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05ddd2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.plot(df.index, res.trend)\n",
    "plt.title('STL Trend')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(df.index, res.seasonal)\n",
    "plt.title('STL Seasonal')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(df.index, res.resid)\n",
    "plt.title('STL Residual')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f070ce82",
   "metadata": {},
   "source": [
    "### Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0926e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train = df.iloc[:-26].copy()\n",
    "test = df.iloc[-26:].copy()\n",
    "len(train), len(test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f3ccc2",
   "metadata": {},
   "source": [
    "### Baselines: Naive and Seasonal Naive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f95366c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Naive: last observed value\n",
    "naive_fc = pd.Series(train['sales'].iloc[-1], index=test.index)\n",
    "\n",
    "# Seasonal naive: repeat last year's same week value (period=52); if not enough history, fallback to naive\n",
    "if len(train) >= 52:\n",
    "    seas_naive_fc = train['sales'].iloc[-52:].reset_index(drop=True)\n",
    "    seas_naive_fc = pd.Series(seas_naive_fc.values[:len(test)], index=test.index)\n",
    "else:\n",
    "    seas_naive_fc = naive_fc.copy()\n",
    "\n",
    "def eval_forecast(y_true, y_pred):\n",
    "    return {\n",
    "        'MAE': mean_absolute_error(y_true, y_pred),\n",
    "        'MAPE': mean_absolute_percentage_error(y_true, y_pred),\n",
    "        'RMSE': mean_squared_error(y_true, y_pred, squared=False),\n",
    "    }\n",
    "\n",
    "baseline_scores = {\n",
    "    'naive': eval_forecast(test['sales'], naive_fc),\n",
    "    'seasonal_naive': eval_forecast(test['sales'], seas_naive_fc),\n",
    "}\n",
    "baseline_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc0d4422",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.plot(train.index, train['sales'], label='Train')\n",
    "plt.plot(test.index, test['sales'], label='Test')\n",
    "plt.plot(test.index, naive_fc, label='Naive FC')\n",
    "plt.title('Naive Forecast vs Actual')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(train.index, train['sales'], label='Train')\n",
    "plt.plot(test.index, test['sales'], label='Test')\n",
    "plt.plot(test.index, seas_naive_fc, label='Seasonal Naive FC')\n",
    "plt.title('Seasonal Naive Forecast vs Actual')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf502cab",
   "metadata": {},
   "source": [
    "### Exponential Smoothing (Holt‑Winters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5473ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "hw = ExponentialSmoothing(\n",
    "    train['sales'],\n",
    "    trend='add',\n",
    "    seasonal='add',\n",
    "    seasonal_periods=52\n",
    ").fit(optimized=True)\n",
    "\n",
    "hw_fc = hw.forecast(len(test))\n",
    "hw_scores = eval_forecast(test['sales'], hw_fc)\n",
    "hw_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06427b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.plot(train.index, train['sales'], label='Train')\n",
    "plt.plot(test.index, test['sales'], label='Test')\n",
    "plt.plot(test.index, hw_fc, label='HW Forecast')\n",
    "plt.title('Holt-Winters Forecast vs Actual')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60fd162f",
   "metadata": {},
   "source": [
    "### SARIMAX (ARIMA with Exogenous Regressors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235cbcc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Simple manual order; in practice use AIC grid search / pmdarima auto_arima\n",
    "order = (1,1,1)\n",
    "seasonal_order = (1,1,1,52)\n",
    "\n",
    "exog_cols = ['promo','price_index','macro_index','holiday']\n",
    "sarimax = SARIMAX(train['sales'], exog=train[exog_cols], order=order, seasonal_order=seasonal_order, enforce_stationarity=False, enforce_invertibility=False)\n",
    "sarimax_res = sarimax.fit(disp=False)\n",
    "\n",
    "sarimax_fc = sarimax_res.forecast(steps=len(test), exog=test[exog_cols])\n",
    "sarimax_scores = eval_forecast(test['sales'], sarimax_fc)\n",
    "sarimax_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d53ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.plot(train.index, train['sales'], label='Train')\n",
    "plt.plot(test.index, test['sales'], label='Test')\n",
    "plt.plot(test.index, sarimax_fc, label='SARIMAX Forecast')\n",
    "plt.title('SARIMAX Forecast vs Actual')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c44572",
   "metadata": {},
   "source": [
    "### Rolling-Origin Cross‑Validation (Walk‑Forward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d9e357",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def walk_forward(df, exog_cols, h=4, initial=78):\n",
    "    # initial ~ 1.5 yrs, forecast horizon h weeks, roll by h\n",
    "    cutpoints = list(range(initial, len(df)-h+1, h))\n",
    "    evals = []\n",
    "    for cp in cutpoints:\n",
    "        tr = df.iloc[:cp]\n",
    "        te = df.iloc[cp:cp+h]\n",
    "        # Fit SARIMAX\n",
    "        mod = SARIMAX(tr['sales'], exog=tr[exog_cols], order=(1,1,1), seasonal_order=(1,1,1,52), enforce_stationarity=False, enforce_invertibility=False)\n",
    "        res = mod.fit(disp=False)\n",
    "        fc = res.forecast(steps=h, exog=te[exog_cols])\n",
    "        ev = eval_forecast(te['sales'], fc)\n",
    "        ev['start'] = tr.index[-1]\n",
    "        evals.append(ev)\n",
    "    return pd.DataFrame(evals)\n",
    "\n",
    "cv_scores = walk_forward(df, exog_cols, h=4, initial=78)\n",
    "cv_scores[['MAE','MAPE','RMSE']].mean().to_dict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6c56bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.plot(cv_scores['start'], cv_scores['RMSE'])\n",
    "plt.title('Walk-Forward RMSE by Split')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7463c03",
   "metadata": {},
   "source": [
    "### Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ecb4294",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "summary = pd.DataFrame({\n",
    "    'MAE': [baseline_scores['naive']['MAE'], baseline_scores['seasonal_naive']['MAE'], hw_scores['MAE'], sarimax_scores['MAE']],\n",
    "    'MAPE': [baseline_scores['naive']['MAPE'], baseline_scores['seasonal_naive']['MAPE'], hw_scores['MAPE'], sarimax_scores['MAPE']],\n",
    "    'RMSE': [baseline_scores['naive']['RMSE'], baseline_scores['seasonal_naive']['RMSE'], hw_scores['RMSE'], sarimax_scores['RMSE']],\n",
    "}, index=['Naive','SeasonalNaive','HoltWinters','SARIMAX'])\n",
    "\n",
    "summary.round(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e9845ac",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "### Practical Guidance\n",
    "- Start with **baselines** (naive/seasonal naive) and beat them.  \n",
    "- Use **Holt‑Winters** for level+trend+seasonality; upgrade to **SARIMAX** to include exogenous drivers.  \n",
    "- Apply **walk‑forward validation**; report average MAE/MAPE/RMSE across splits.  \n",
    "- Combine forecasts (simple average) to reduce variance in practice.\n",
    "\n",
    "### References (non‑link citations)\n",
    "1. Hyndman & Athanasopoulos — *Forecasting: Principles and Practice*.  \n",
    "2. Box, Jenkins, Reinsel & Ljung — *Time Series Analysis*.  \n",
    "3. Greene — *Econometric Analysis*.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
