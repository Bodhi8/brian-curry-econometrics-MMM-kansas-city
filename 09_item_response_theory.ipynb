{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad2e81f3",
   "metadata": {},
   "source": [
    "\n",
    "# Item Response Theory (IRT) — 1PL (Rasch) with Bonus 2PL — Python Notebook\n",
    "\n",
    "**When to Use**  \n",
    "- Measuring a **latent trait** (ability, brand affinity, satisfaction) from item responses (correct/incorrect, agree/disagree).  \n",
    "- Building **short, adaptive questionnaires** that are comparable across populations and time.\n",
    "\n",
    "**Best Application**  \n",
    "- Psychometrics, **brand loyalty/sentiment scales**, and survey measurement where items have varying difficulty.  \n",
    "- **Computerized adaptive testing (CAT)** or respondent scoring from partial item sets.\n",
    "\n",
    "**When Not to Use**  \n",
    "- When items do not measure a **single underlying construct** (unidimensionality violated). Use factor analysis or multidimensional IRT.  \n",
    "- With purely **continuous outcomes**; consider latent-variable SEM/GLMs instead.\n",
    "\n",
    "**How to Interpret Results**  \n",
    "- **Person ability (θ)**: latent trait level per respondent on a standardized scale (mean≈0).  \n",
    "- **Item difficulty (b)**: trait level where P(correct/agree)=0.5 (higher b = harder/stricter item).  \n",
    "- **Item discrimination (a)** (2PL): slope/steepness; higher a = more information around b.  \n",
    "- Use **item characteristic curves (ICC)** and **test information** to judge measurement precision by trait level.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07db7550",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.special import expit\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "pd.set_option('display.max_columns', 200)\n",
    "plt.rcParams['figure.figsize'] = (8,4)\n",
    "rng = np.random.default_rng(123)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a499fbfb",
   "metadata": {},
   "source": [
    "### Data: Simulate respondent abilities and item parameters (2PL ground truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f327b40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "N = 500\n",
    "J = 15\n",
    "\n",
    "theta_true = rng.normal(0, 1, size=N)\n",
    "a_true = rng.lognormal(mean=0.1, sigma=0.2, size=J)\n",
    "b_true = rng.normal(0, 1, size=J)\n",
    "\n",
    "P = expit((theta_true[:,None] - b_true[None,:]) * a_true[None,:])\n",
    "Y = rng.binomial(1, P)\n",
    "Y[:5,:5]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c454de5",
   "metadata": {},
   "source": [
    "## Fit 1PL (Rasch) via Joint MLE with Identifiability Constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3d6d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def pack(theta, b):\n",
    "    return np.r_[theta[:-1], b[:-1]]\n",
    "\n",
    "def unpack(w, N, J):\n",
    "    theta_free = w[:N-1]\n",
    "    b_free = w[N-1:]\n",
    "    theta = np.r_[theta_free, -theta_free.sum()]\n",
    "    b = np.r_[b_free, -b_free.sum()]\n",
    "    return theta, b\n",
    "\n",
    "def nll_rasch(w, Y, l2=1e-3):\n",
    "    N, J = Y.shape\n",
    "    theta, b = unpack(w, N, J)\n",
    "    eta = theta[:,None] - b[None,:]\n",
    "    p = expit(eta)\n",
    "    eps = 1e-9\n",
    "    p = np.clip(p, eps, 1-eps)\n",
    "    ll = Y*np.log(p) + (1-Y)*np.log(1-p)\n",
    "    pen = l2*(np.sum(theta**2) + np.sum(b**2))\n",
    "    return -ll.sum() + pen\n",
    "\n",
    "theta0 = (Y.mean(axis=1) - 0.5) * 2.0\n",
    "b0 = -(Y.mean(axis=0) - 0.5) * 2.0\n",
    "w0 = pack(theta0, b0)\n",
    "\n",
    "res = minimize(nll_rasch, w0, args=(Y, 1e-3), method='L-BFGS-B')\n",
    "theta_hat, b_hat = unpack(res.x, N, J)\n",
    "\n",
    "res.success, float(res.fun)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6fea71a",
   "metadata": {},
   "source": [
    "### Rasch Diagnostics: Person/Item summaries and calibration plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3873c17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "theta_df = pd.DataFrame({'theta_hat': theta_hat})\n",
    "item_df = pd.DataFrame({'b_hat': b_hat, 'a_assumed': 1.0, 'p_correct': Y.mean(axis=0)})\n",
    "theta_df.describe(), item_df.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1ccaa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "P_hat_rasch = expit(theta_hat[:,None] - b_hat[None,:])\n",
    "obs = Y.mean(axis=0)\n",
    "pred = P_hat_rasch.mean(axis=0)\n",
    "\n",
    "plt.scatter(obs, pred)\n",
    "plt.plot([0,1],[0,1],'k--')\n",
    "plt.xlabel('Observed mean correct (per item)')\n",
    "plt.ylabel('Predicted mean (Rasch)')\n",
    "plt.title('Item Calibration: Rasch')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f0efdc",
   "metadata": {},
   "source": [
    "### Item Characteristic Curves (ICC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9aea964",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "theta_grid = np.linspace(-3, 3, 200)\n",
    "plt.figure()\n",
    "for j in range(J):\n",
    "    p = expit(theta_grid - b_hat[j])\n",
    "    plt.plot(theta_grid, p, alpha=0.5)\n",
    "plt.xlabel('Ability θ')\n",
    "plt.ylabel('P(correct)')\n",
    "plt.title('Rasch ICCs (a=1)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31917843",
   "metadata": {},
   "source": [
    "### Test Information (Rasch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced70ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def info_rasch(theta, b):\n",
    "    p = expit(theta - b)\n",
    "    return p*(1-p)\n",
    "\n",
    "info = np.zeros_like(theta_grid)\n",
    "for j in range(J):\n",
    "    info += info_rasch(theta_grid, b_hat[j])\n",
    "plt.plot(theta_grid, info)\n",
    "plt.xlabel('Ability θ')\n",
    "plt.ylabel('Information (sum over items)')\n",
    "plt.title('Test Information (Rasch)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d23a239f",
   "metadata": {},
   "source": [
    "### Scoring: Estimate θ for New Respondents Given Fixed Items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403f0e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "new_Y = np.array([\n",
    "    [1,1,1,1,1, 1,0,1,0,0, 1,0,1,1,0],\n",
    "    [0,0,0,0,0, 0,0,1,0,0, 1,0,0,0,0],\n",
    "    [1,0,1,0,1, 0,1,0,1,0, 1,0,1,0,1],\n",
    "])\n",
    "\n",
    "def estimate_theta_fixed_items(y_row, b, l2=1e-3):\n",
    "    mask = ~np.isnan(y_row)\n",
    "    y = y_row[mask]\n",
    "    bj = b[mask]\n",
    "    def nll(theta):\n",
    "        p = expit(theta - bj)\n",
    "        eps=1e-9\n",
    "        p = np.clip(p, eps, 1-eps)\n",
    "        return -(y*np.log(p) + (1-y)*np.log(1-p)).sum() + l2*theta**2\n",
    "    r = minimize(lambda th: nll(th[0]), x0=np.array([0.0]), method='L-BFGS-B')\n",
    "    return r.x[0]\n",
    "\n",
    "thetas_new = np.array([estimate_theta_fixed_items(row, b_hat) for row in new_Y])\n",
    "thetas_new\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f29fd74d",
   "metadata": {},
   "source": [
    "## Bonus: 2PL (a, b) via Alternating Optimization (compact demo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d824854",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def nll_items_ab(params, theta, Y, l2a=1e-2, l2b=1e-3):\n",
    "    J = Y.shape[1]\n",
    "    a = params[:J]\n",
    "    b = params[J:]\n",
    "    p = expit((theta[:,None] - b[None,:]) * a[None,:])\n",
    "    eps=1e-9\n",
    "    p = np.clip(p, eps, 1-eps)\n",
    "    ll = Y*np.log(p) + (1-Y)*np.log(1-p)\n",
    "    pen = l2a*np.sum((a-1.0)**2) + l2b*np.sum(b**2) + 100*np.sum((a<0)*(-a))\n",
    "    return -(ll.sum() - pen)\n",
    "\n",
    "def nll_theta(theta, a, b, Y, l2=1e-3):\n",
    "    p = expit((theta[:,None] - b[None,:]) * a[None,:])\n",
    "    eps=1e-9\n",
    "    p = np.clip(p, eps, 1-eps)\n",
    "    ll = Y*np.log(p) + (1-Y)*np.log(1-p)\n",
    "    pen = l2*np.sum(theta**2)\n",
    "    return -(ll.sum() - pen)\n",
    "\n",
    "a_hat = np.ones(J)\n",
    "b2_hat = b_hat.copy()\n",
    "theta2 = theta_hat.copy()\n",
    "\n",
    "for it in range(5):\n",
    "    x0 = np.r_[a_hat, b2_hat]\n",
    "    res_ab = minimize(nll_items_ab, x0, args=(theta2, Y), method='L-BFGS-B')\n",
    "    ab = res_ab.x\n",
    "    a_hat = np.maximum(ab[:J], 0.05)\n",
    "    b2_hat = ab[J:] - ab[J:].mean()\n",
    "    res_th = minimize(lambda th: nll_theta(th, a_hat, b2_hat, Y), theta2, method='L-BFGS-B')\n",
    "    theta2 = res_th.x - res_th.x.mean()\n",
    "\n",
    "P_hat_2pl = expit((theta2[:,None] - b2_hat[None,:]) * a_hat[None,:])\n",
    "obs = Y.mean(axis=0)\n",
    "pred_rasch = expit(theta_hat[:,None] - b_hat[None,:]).mean(axis=0)\n",
    "pred_2pl = P_hat_2pl.mean(axis=0)\n",
    "\n",
    "cal = pd.DataFrame({'obs': obs, 'rasch': pred_rasch, 'twopl': pred_2pl})\n",
    "cal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5ad08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.scatter(cal['obs'], cal['rasch'], label='Rasch', alpha=0.7)\n",
    "plt.scatter(cal['obs'], cal['twopl'], label='2PL (alt opt)', alpha=0.7)\n",
    "plt.plot([0,1],[0,1],'k--')\n",
    "plt.xlabel('Observed mean correct (per item)')\n",
    "plt.ylabel('Predicted mean')\n",
    "plt.title('Calibration: Rasch vs 2PL')\n",
    "plt.legend(); plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cffa7fc",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "### Practical Guidance\n",
    "- Start with **Rasch (1PL)** for stability and comparability; move to **2PL** if items differ in discrimination.  \n",
    "- Center parameters for identifiability (mean θ = 0, mean b = 0), and regularize lightly.  \n",
    "- For production use with priors and missing data, consider **Bayesian IRT** (PyMC/Stan) and **CAT** logic for adaptive testing.\n",
    "\n",
    "### References (non‑link citations)\n",
    "1. Embretson & Reise — *Item Response Theory for Psychologists*.  \n",
    "2. Baker — *The Basics of Item Response Theory*.  \n",
    "3. Rossi, Allenby & McCulloch — *Bayesian Statistics and Marketing* (IRT applications).\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
