{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88eb243a",
   "metadata": {},
   "source": [
    "\n",
    "# Media Mix Modeling (MMM) — Python Notebook\n",
    "\n",
    "**When to Use**  \n",
    "- You need **channel-level impact** estimates using **aggregate** (weekly/monthly) spend + outcome (sales/revenue) data.  \n",
    "- You’re allocating **budgets across channels** (TV, Paid Social, Search, OOH, etc.) and user-level tracking is incomplete or deprecated.\n",
    "\n",
    "**Best Application**  \n",
    "- Strategic planning and **budget reallocation** across channels.  \n",
    "- Estimating **diminishing returns** (saturation) and **carryover** (adstock).  \n",
    "- Running **what-if** scenarios on spend changes.\n",
    "\n",
    "**When Not to Use**  \n",
    "- **Short-term tactical** optimization (creative/keyword bidding); use MTA/experimentation instead.  \n",
    "- Highly **non-stationary** environments with rapid structural breaks and minimal history.  \n",
    "- When you must attribute at the **user or creative** level.\n",
    "\n",
    "**How to Interpret Results**  \n",
    "- **Coefficients** reflect the relationship between *transformed* media (adstock + saturation) and outcome.  \n",
    "- **Channel contributions** estimate each channel’s share of modeled sales.  \n",
    "- **Marginal ROI (mROI)** indicates which channel yields the **biggest incremental return** for the next dollar of spend (at current levels).  \n",
    "- Use results for **budget shifts**, not as immutable truth—validate with **experiments/geo tests**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c818437",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "pd.set_option('display.max_columns', 100)\n",
    "plt.rcParams['figure.figsize'] = (8,4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163602d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from io import StringIO\n",
    "\n",
    "csv_data = StringIO(\"\"\"\n",
    "week,TV,Radio,Newspaper,Sales\n",
    "1,230.1,37.8,69.2,22.1\n",
    "2,44.5,39.3,45.1,10.4\n",
    "3,17.2,45.9,69.3,9.3\n",
    "4,151.5,41.3,58.5,18.5\n",
    "5,180.8,10.8,58.4,12.9\n",
    "6,8.7,48.9,75,7.2\n",
    "7,57.5,32.8,23.5,11.8\n",
    "8,120.2,19.6,11.6,13.2\n",
    "9,8.6,2.1,1,4.8\n",
    "10,199.8,2.6,21.2,10.6\n",
    "11,66.1,5.8,24.2,8.6\n",
    "12,214.7,24,4,17.4\n",
    "13,23.8,35.1,65.9,9.2\n",
    "14,97.5,7.6,7.2,9.7\n",
    "15,204.1,32.9,46,19\n",
    "16,195.4,47.7,52.9,22.4\n",
    "17,67.8,36.6,114,12.5\n",
    "18,281.4,39.6,55.8,24.4\n",
    "19,69.2,20.5,18.3,11.3\n",
    "20,147.3,23.9,19.1,14.6\n",
    "21,218.4,27.5,25.0,18.0\n",
    "22,237.4,5.1,23.5,12.5\n",
    "23,13.2,15.9,49.6,5.6\n",
    "24,228.3,16.9,26.2,15.5\n",
    "25,62.3,12.6,18.3,9.7\n",
    "26,262.9,3.5,19.5,12.0\n",
    "27,142.9,29.3,12.6,15.0\n",
    "28,240.1,16.7,22.9,16.7\n",
    "29,248.8,27.1,22.9,18.9\n",
    "30,70.6,16.0,40.8,10.5\n",
    "\"\"\")\n",
    "df = pd.read_csv(csv_data)\n",
    "df = df.sort_values('week').reset_index(drop=True)\n",
    "\n",
    "# Example seasonal effect: every 4th week high (toy illustration)\n",
    "df['seasonality'] = ((df['week'] % 4)==0).astype(int)\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bea4f0a",
   "metadata": {},
   "source": [
    "### Adstock & Saturation Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6ce160",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def adstock(x, rate=0.5):\n",
    "    carry = 0.0\n",
    "    out = []\n",
    "    for xi in x:\n",
    "        carry = xi + rate * carry\n",
    "        out.append(carry)\n",
    "    return np.array(out, dtype=float)\n",
    "\n",
    "def hill_saturation(x, alpha=100.0, gamma=1.5):\n",
    "    x = np.asarray(x, dtype=float)\n",
    "    return np.power(x, gamma) / (np.power(alpha, gamma) + np.power(x, gamma))\n",
    "\n",
    "# Apply per channel\n",
    "for ch in ['TV','Radio','Newspaper']:\n",
    "    df[f'{ch}_adstock'] = adstock(df[ch].values, rate=0.5)\n",
    "    df[f'{ch}_sat'] = hill_saturation(df[f'{ch}_adstock'].values, alpha=120.0, gamma=1.5)\n",
    "\n",
    "df[['week','TV_sat','Radio_sat','Newspaper_sat']].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43afdc3c",
   "metadata": {},
   "source": [
    "### Model: Ridge Regression with TimeSeries CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eae2e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "features = ['TV_sat','Radio_sat','Newspaper_sat','seasonality']\n",
    "target = 'Sales'\n",
    "\n",
    "X = df[features].values\n",
    "y = df[target].values\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "alphas = np.logspace(-4, 3, 50)\n",
    "\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "ridge = Pipeline([\n",
    "    ('scaler', StandardScaler(with_mean=True, with_std=True)),\n",
    "    ('model', RidgeCV(alphas=alphas, cv=tscv))\n",
    "])\n",
    "\n",
    "ridge.fit(X, y)\n",
    "alpha_ = ridge.named_steps['model'].alpha_\n",
    "coef_ = ridge.named_steps['model'].coef_\n",
    "intercept_ = ridge.named_steps['model'].intercept_\n",
    "\n",
    "print(\"Selected alpha:\", alpha_)\n",
    "print(\"Intercept:\", intercept_)\n",
    "pd.Series(coef_, index=features).to_frame('coefficient')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "326f11b1",
   "metadata": {},
   "source": [
    "### In-Sample Fit & Diagnostics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55de5863",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df['pred'] = ridge.predict(X)\n",
    "\n",
    "from sklearn.metrics import r2_score, mean_absolute_error\n",
    "r2 = r2_score(y, df['pred'])\n",
    "mae = mean_absolute_error(y, df['pred'])\n",
    "print(f\"R^2: {r2:.3f} | MAE: {mae:.3f}\")\n",
    "\n",
    "plt.plot(df['week'], y, label='Actual')\n",
    "plt.plot(df['week'], df['pred'], label='Predicted')\n",
    "plt.title('Actual vs Predicted Sales')\n",
    "plt.xlabel('Week')\n",
    "plt.ylabel('Sales')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b08e8a",
   "metadata": {},
   "source": [
    "### Channel Contributions (Decomposition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36388128",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "coefs = pd.Series(ridge.named_steps['model'].coef_, index=features)\n",
    "\n",
    "# Contribution via linear terms on transformed media\n",
    "contri = pd.DataFrame(index=df.index)\n",
    "for ch in ['TV_sat','Radio_sat','Newspaper_sat']:\n",
    "    contri[ch] = coefs[ch] * df[ch+'_sat']\n",
    "\n",
    "contri['seasonality'] = coefs['seasonality'] * df['seasonality']\n",
    "contri['baseline'] = ridge.named_steps['model'].intercept_\n",
    "contri['pred'] = contri.sum(axis=1)\n",
    "\n",
    "contri_sum = contri[['TV_sat','Radio_sat','Newspaper_sat','seasonality']].sum()\n",
    "share = (contri_sum / contri_sum.sum()).sort_values(ascending=False)\n",
    "share.to_frame('contribution_share').style.format({'contribution_share': '{:.2%}'})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b11b7f",
   "metadata": {},
   "source": [
    "### Marginal ROI (mROI) at Current Spend Levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce9818d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def dhill_dx(x, alpha=120.0, gamma=1.5):\n",
    "    num = gamma * np.power(x, gamma-1) * np.power(alpha, gamma)\n",
    "    den = np.power(alpha, gamma) + np.power(x, gamma)\n",
    "    return num / (den**2)\n",
    "\n",
    "def dadstock_dx(rate=0.5):\n",
    "    return 1.0  # current period sensitivity\n",
    "\n",
    "mroi = {}\n",
    "for ch in ['TV','Radio','Newspaper']:\n",
    "    x = df[f'{ch}_adstock'].values\n",
    "    coef = coefs[f'{ch}_sat']\n",
    "    cur_x = x[-1]\n",
    "    d_sales_d_adstock = coef * dhill_dx(cur_x, alpha=120.0, gamma=1.5)\n",
    "    d_sales_d_spend = d_sales_d_adstock * dadstock_dx(rate=0.5)\n",
    "    mroi[ch] = float(d_sales_d_spend)\n",
    "\n",
    "pd.Series(mroi).sort_values(ascending=False).to_frame('mROI (ΔSales per $1 spend)').round(6)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b40e6f5a",
   "metadata": {},
   "source": [
    "### Simple Budget Reallocation Heuristic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87af4e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "extra_budget = 10.0\n",
    "mroi_series = pd.Series(mroi).clip(lower=0)\n",
    "weights = mroi_series / mroi_series.sum() if mroi_series.sum() > 0 else pd.Series({k: 1/3 for k in mroi_series.index})\n",
    "allocation = (weights * extra_budget).round(2)\n",
    "allocation.to_frame('recommended_extra_spend_$')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c5444b0",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "### Notes\n",
    "- This is a compact, educational MMM; production models should include: holiday/price/promo controls, multiple saturation forms, channel interactions, priors (Bayesian MMM), and holdout validation (e.g., geo-experiments).  \n",
    "- Always **triangulate** with experiments and directional business knowledge.\n",
    "\n",
    "### References (non-link citations)\n",
    "1. McCarthy & Perlich, *Modern Approaches to Media Mix Modeling*.  \n",
    "2. Greene, *Econometric Analysis*.  \n",
    "3. Rossi, Allenby & McCulloch, *Bayesian Statistics and Marketing*.  \n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
